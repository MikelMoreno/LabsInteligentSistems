if (current == problem$target){
return(TRUE)
}else if(current < problem$target){
#compruebas con cada pizza restante desde 1 hasta "target" (pk obviamente no vas a comprobar la pizza 90 para un target de 8)
i = which.min(state) #nos devuelve la posicion del primer false (nos indica donde vamos)
if (i == (length(state)-1)){
print("true")
return(TRUE)
}else{
print("false")
return(FALSE)
}
}
source('~/GitHub/LabsInteligentSistems/Search problem template/methods/Random Hill Climber.R')
# Setup the environment
rm(list=ls())
cat("\014")
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
dir()
library(ggplot2)
library(caret)
# Read csv
csv_dataframe = read.csv(file.path("../data/2020 - 2019 world happiness.csv"))
# structure of the data relation we are going to use in the first problem (relation between GPD per capita and the obtained score)
ggplot(csv_dataframe, aes(x = GDP.per.capita, y = Score)) + geom_point()
# value for random data-partitioning
number = 5678
# vector (like an array) for MAE comparisons
ObtainedMAEs_lm = vector()
for (i in 1:10) {
# create partitions
set.seed(number)
number = number + 5
#select 80% of the data
training_data_in_indexes = createDataPartition(
csv_dataframe$Overall.rank,
times = 1,
p = 0.8,
list = FALSE
)
training_dataframe = csv_dataframe[training_data_in_indexes,] # get the 80% of the data for training
testing_dataframe = csv_dataframe[-training_data_in_indexes,] # the rest (20%) for testing
# adapt the format of the TRAINING dataframe
training_dataframe_parsed = data.frame(
x6 = training_dataframe$Social.support,
x5 = training_dataframe$Healthy.life.expectancy,
x4 = training_dataframe$Freedom.to.make.life.choices,
x3 = training_dataframe$Generosity,
x2 = training_dataframe$Perceptions.of.corruption,
x1 = training_dataframe$GDP.per.capita,
x0 = 1,
y  = training_dataframe$Score,
h  = 0,
e  = 0
)
# adapt the format of the TEST dataframe
testing_dataframe_parsed = data.frame(
x6 = testing_dataframe$Social.support,
x5 = testing_dataframe$Healthy.life.expectancy,
x4 = testing_dataframe$Freedom.to.make.life.choices,
x3 = testing_dataframe$Generosity,
x2 = testing_dataframe$Perceptions.of.corruption,
x1 = testing_dataframe$GDP.per.capita,
x0 = 1,
y  = testing_dataframe$Score,
h  = 0,
e  = 0
)
# use lm() function
model = lm(y ~ x1+x2+x3+x4+x5+x6, data = training_dataframe_parsed)
# add hypothesis and error values to the training dataframe
training_dataframe_parsed$h = predict(model, training_dataframe_parsed)
training_dataframe_parsed$e = training_dataframe_parsed$y - training_dataframe_parsed$h
# plot the trained model
print(ggplot(training_dataframe_parsed) +
geom_point(aes(x = x1, y = y, col = "Data")) +
geom_point(aes(x = x1, y = h, col = "Model hypothesis")) +
geom_line(aes(x = x1, y = h, col = "Model hypothesis")) +
labs(caption=paste0(
"  w6=", round(coef(model)[[7]], digits=4),
"  w5=", round(coef(model)[[6]], digits=4),
"  w4=", round(coef(model)[[5]], digits=4),
"  w3=", round(coef(model)[[4]], digits=4),
"  w2=", round(coef(model)[[3]], digits=4),
"  w1=", round(coef(model)[[2]], digits=4),
"  w0=", round(coef(model)[[1]], digits=4)
))
)
# print information about the trained model
print(paste0(" Calculated weights in training data and error"))
print(paste0(
" w6=", round(coef(model)[[7]], digits=5),
" w5=", round(coef(model)[[6]], digits=5),
" w4=", round(coef(model)[[5]], digits=5),
" w3=", round(coef(model)[[4]], digits=5),
" w2=", round(coef(model)[[3]], digits=5),
" w1=", round(coef(model)[[2]], digits=5),
" w0=", round(coef(model)[[1]], digits=5),
" error=", round(mean(abs(training_dataframe_parsed$e)), digits=5))
)
# test the created model comparing it againts test-dataframe (hipothesys=h vs reality=y)
testing_dataframe_parsed$h =
coef(model)[[7]]*testing_dataframe_parsed$x6 +
coef(model)[[6]]*testing_dataframe_parsed$x5 +
coef(model)[[5]]*testing_dataframe_parsed$x4 +
coef(model)[[4]]*testing_dataframe_parsed$x3 +
coef(model)[[3]]*testing_dataframe_parsed$x2 +
coef(model)[[2]]*testing_dataframe_parsed$x1 +
coef(model)[[1]]*testing_dataframe_parsed$x0
testing_dataframe_parsed$e = testing_dataframe_parsed$y - testing_dataframe_parsed$h
# print MAE
print(paste0(" Comparing calculated weights against real test value"))
print(paste0(" MAE = ", mean(abs(testing_dataframe_parsed$e))))
# print R-squared values
print(paste0(" Multiple R-squared = ", summary(model)$r.squared))
print(paste0(" Adjusted R-squared = ", summary(model)$adj.r.squared))
ObtainedMAEs_lm = append(ObtainedMAEs_lm, mean(abs(testing_dataframe_parsed$e)))
invisible(readline(prompt = "Press a key to start next iteration"))
}
summary(model)
# value for random data-partitioning
number = 5678
# vector (like an array) for MAE comparisons
ObtainedMAEs_lm = vector()
for (i in 1:10) {
# create partitions
set.seed(number)
number = number + 5
#select 80% of the data
training_data_in_indexes = createDataPartition(
csv_dataframe$Overall.rank,
times = 1,
p = 0.8,
list = FALSE
)
training_dataframe = csv_dataframe[training_data_in_indexes,] # get the 80% of the data for training
testing_dataframe = csv_dataframe[-training_data_in_indexes,] # the rest (20%) for testing
# adapt the format of the TRAINING dataframe
training_dataframe_parsed = data.frame(
x6 = training_dataframe$Social.support,
x5 = training_dataframe$Healthy.life.expectancy,
x4 = training_dataframe$Freedom.to.make.life.choices,
x3 = training_dataframe$Generosity,
x2 = training_dataframe$Perceptions.of.corruption,
x1 = training_dataframe$GDP.per.capita,
x0 = 1,
y  = training_dataframe$Score,
h  = 0,
e  = 0
)
# adapt the format of the TEST dataframe
testing_dataframe_parsed = data.frame(
x6 = testing_dataframe$Social.support,
x5 = testing_dataframe$Healthy.life.expectancy,
x4 = testing_dataframe$Freedom.to.make.life.choices,
x3 = testing_dataframe$Generosity,
x2 = testing_dataframe$Perceptions.of.corruption,
x1 = testing_dataframe$GDP.per.capita,
x0 = 1,
y  = testing_dataframe$Score,
h  = 0,
e  = 0
)
# use lm() function
model = lm(y ~ x1+x2+x3+x4+x5+x6, data = training_dataframe_parsed)
# add hypothesis and error values to the training dataframe
training_dataframe_parsed$h = predict(model, training_dataframe_parsed)
training_dataframe_parsed$e = training_dataframe_parsed$y - training_dataframe_parsed$h
# plot the trained model
print(ggplot(training_dataframe_parsed) +
geom_point(aes(x = x1, y = y, col = "Data")) +
geom_point(aes(x = x1, y = h, col = "Model hypothesis")) +
geom_line(aes(x = x1, y = h, col = "Model hypothesis")) +
labs(caption=paste0(
"  w6=", round(coef(model)[[7]], digits=4),
"  w5=", round(coef(model)[[6]], digits=4),
"  w4=", round(coef(model)[[5]], digits=4),
"  w3=", round(coef(model)[[4]], digits=4),
"  w2=", round(coef(model)[[3]], digits=4),
"  w1=", round(coef(model)[[2]], digits=4),
"  w0=", round(coef(model)[[1]], digits=4)
))
)
# print information about the trained model
print(paste0(" Calculated weights in training data and error"))
print(paste0(
" w6=", round(coef(model)[[7]], digits=5),
" w5=", round(coef(model)[[6]], digits=5),
" w4=", round(coef(model)[[5]], digits=5),
" w3=", round(coef(model)[[4]], digits=5),
" w2=", round(coef(model)[[3]], digits=5),
" w1=", round(coef(model)[[2]], digits=5),
" w0=", round(coef(model)[[1]], digits=5),
" error=", round(mean(abs(training_dataframe_parsed$e)), digits=5))
)
# test the created model comparing it againts test-dataframe (hipothesys=h vs reality=y)
testing_dataframe_parsed$h =
coef(model)[[7]]*testing_dataframe_parsed$x6 +
coef(model)[[6]]*testing_dataframe_parsed$x5 +
coef(model)[[5]]*testing_dataframe_parsed$x4 +
coef(model)[[4]]*testing_dataframe_parsed$x3 +
coef(model)[[3]]*testing_dataframe_parsed$x2 +
coef(model)[[2]]*testing_dataframe_parsed$x1 +
coef(model)[[1]]*testing_dataframe_parsed$x0
testing_dataframe_parsed$e = testing_dataframe_parsed$y - testing_dataframe_parsed$h
#print the summary
summary(model)
# print MAE
print(paste0(" Comparing calculated weights against real test value"))
print(paste0(" MAE = ", mean(abs(testing_dataframe_parsed$e))))
# print R-squared values
print(paste0(" Multiple R-squared = ", summary(model)$r.squared))
print(paste0(" Adjusted R-squared = ", summary(model)$adj.r.squared))
ObtainedMAEs_lm = append(ObtainedMAEs_lm, mean(abs(testing_dataframe_parsed$e)))
invisible(readline(prompt = "Press a key to start next iteration"))
}
# Setup the environment
rm(list=ls())
cat("\014")
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
dir()
library(ggplot2)
library(caret)
# Read csv
csv_dataframe = read.csv(file.path("../data/2020 - 2019 world happiness.csv"))
# structure of the data relation we are going to use in the first problem (relation between GPD per capita and the obtained score)
ggplot(csv_dataframe, aes(x = GDP.per.capita, y = Score)) + geom_point()
# value for random data-partitioning
number = 5678
# vector (like an array) for MAE comparisons
ObtainedMAEs_lm = vector()
for (i in 1:10) {
# create partitions
set.seed(number)
number = number + 5
#select 80% of the data
training_data_in_indexes = createDataPartition(
csv_dataframe$Overall.rank,
times = 1,
p = 0.8,
list = FALSE
)
training_dataframe = csv_dataframe[training_data_in_indexes,] # get the 80% of the data for training
testing_dataframe = csv_dataframe[-training_data_in_indexes,] # the rest (20%) for testing
# adapt the format of the TRAINING dataframe
training_dataframe_parsed = data.frame(
x6 = training_dataframe$Social.support,
x5 = training_dataframe$Healthy.life.expectancy,
x4 = training_dataframe$Freedom.to.make.life.choices,
x3 = training_dataframe$Generosity,
x2 = training_dataframe$Perceptions.of.corruption,
x1 = training_dataframe$GDP.per.capita,
x0 = 1,
y  = training_dataframe$Score,
h  = 0,
e  = 0
)
# adapt the format of the TEST dataframe
testing_dataframe_parsed = data.frame(
x6 = testing_dataframe$Social.support,
x5 = testing_dataframe$Healthy.life.expectancy,
x4 = testing_dataframe$Freedom.to.make.life.choices,
x3 = testing_dataframe$Generosity,
x2 = testing_dataframe$Perceptions.of.corruption,
x1 = testing_dataframe$GDP.per.capita,
x0 = 1,
y  = testing_dataframe$Score,
h  = 0,
e  = 0
)
# use lm() function
model = lm(y ~ x1+x2+x3+x4+x5+x6, data = training_dataframe_parsed)
# add hypothesis and error values to the training dataframe
training_dataframe_parsed$h = predict(model, training_dataframe_parsed)
training_dataframe_parsed$e = training_dataframe_parsed$y - training_dataframe_parsed$h
# plot the trained model
print(ggplot(training_dataframe_parsed) +
geom_point(aes(x = x1, y = y, col = "Data")) +
geom_point(aes(x = x1, y = h, col = "Model hypothesis")) +
geom_line(aes(x = x1, y = h, col = "Model hypothesis")) +
labs(caption=paste0(
"  w6=", round(coef(model)[[7]], digits=4),
"  w5=", round(coef(model)[[6]], digits=4),
"  w4=", round(coef(model)[[5]], digits=4),
"  w3=", round(coef(model)[[4]], digits=4),
"  w2=", round(coef(model)[[3]], digits=4),
"  w1=", round(coef(model)[[2]], digits=4),
"  w0=", round(coef(model)[[1]], digits=4)
))
)
# print information about the trained model
print(paste0(" Calculated weights in training data and error"))
print(paste0(
" w6=", round(coef(model)[[7]], digits=5),
" w5=", round(coef(model)[[6]], digits=5),
" w4=", round(coef(model)[[5]], digits=5),
" w3=", round(coef(model)[[4]], digits=5),
" w2=", round(coef(model)[[3]], digits=5),
" w1=", round(coef(model)[[2]], digits=5),
" w0=", round(coef(model)[[1]], digits=5),
" error=", round(mean(abs(training_dataframe_parsed$e)), digits=5))
)
# test the created model comparing it againts test-dataframe (hipothesys=h vs reality=y)
testing_dataframe_parsed$h =
coef(model)[[7]]*testing_dataframe_parsed$x6 +
coef(model)[[6]]*testing_dataframe_parsed$x5 +
coef(model)[[5]]*testing_dataframe_parsed$x4 +
coef(model)[[4]]*testing_dataframe_parsed$x3 +
coef(model)[[3]]*testing_dataframe_parsed$x2 +
coef(model)[[2]]*testing_dataframe_parsed$x1 +
coef(model)[[1]]*testing_dataframe_parsed$x0
testing_dataframe_parsed$e = testing_dataframe_parsed$y - testing_dataframe_parsed$h
#print the summary
summary(model)
# print MAE
print(paste0(" Comparing calculated weights against real test value"))
print(paste0(" MAE = ", mean(abs(testing_dataframe_parsed$e))))
# print R-squared values
print(paste0(" Multiple R-squared = ", summary(model)$r.squared))
print(paste0(" Adjusted R-squared = ", summary(model)$adj.r.squared))
ObtainedMAEs_lm = append(ObtainedMAEs_lm, mean(abs(testing_dataframe_parsed$e)))
invisible(readline(prompt = "Press a key to start next iteration"))
}
#print the summary
summary(model)
for (i in 1:10) {
# create partitions
set.seed(number)
number = number + 5
#select 80% of the data
training_data_in_indexes = createDataPartition(
csv_dataframe$Overall.rank,
times = 1,
p = 0.8,
list = FALSE
)
training_dataframe = csv_dataframe[training_data_in_indexes,] # get the 80% of the data for training
testing_dataframe = csv_dataframe[-training_data_in_indexes,] # the rest (20%) for testing
# adapt the format of the TRAINING dataframe
training_dataframe_parsed = data.frame(
x6 = training_dataframe$Social.support,
x5 = training_dataframe$Healthy.life.expectancy,
x4 = training_dataframe$Freedom.to.make.life.choices,
x3 = training_dataframe$Generosity,
x2 = training_dataframe$Perceptions.of.corruption,
x1 = training_dataframe$GDP.per.capita,
x0 = 1,
y  = training_dataframe$Score,
h  = 0,
e  = 0
)
# adapt the format of the TEST dataframe
testing_dataframe_parsed = data.frame(
x6 = testing_dataframe$Social.support,
x5 = testing_dataframe$Healthy.life.expectancy,
x4 = testing_dataframe$Freedom.to.make.life.choices,
x3 = testing_dataframe$Generosity,
x2 = testing_dataframe$Perceptions.of.corruption,
x1 = testing_dataframe$GDP.per.capita,
x0 = 1,
y  = testing_dataframe$Score,
h  = 0,
e  = 0
)
# use lm() function
model = lm(y ~ x1+x2+x3+x4+x5+x6, data = training_dataframe_parsed)
# add hypothesis and error values to the training dataframe
training_dataframe_parsed$h = predict(model, training_dataframe_parsed)
training_dataframe_parsed$e = training_dataframe_parsed$y - training_dataframe_parsed$h
# plot the trained model
print(ggplot(training_dataframe_parsed) +
geom_point(aes(x = x1, y = y, col = "Data")) +
geom_point(aes(x = x1, y = h, col = "Model hypothesis")) +
geom_line(aes(x = x1, y = h, col = "Model hypothesis")) +
labs(caption=paste0(
"  w6=", round(coef(model)[[7]], digits=4),
"  w5=", round(coef(model)[[6]], digits=4),
"  w4=", round(coef(model)[[5]], digits=4),
"  w3=", round(coef(model)[[4]], digits=4),
"  w2=", round(coef(model)[[3]], digits=4),
"  w1=", round(coef(model)[[2]], digits=4),
"  w0=", round(coef(model)[[1]], digits=4)
))
)
# print information about the trained model
print(paste0(" Calculated weights in training data and error"))
print(paste0(
" w6=", round(coef(model)[[7]], digits=5),
" w5=", round(coef(model)[[6]], digits=5),
" w4=", round(coef(model)[[5]], digits=5),
" w3=", round(coef(model)[[4]], digits=5),
" w2=", round(coef(model)[[3]], digits=5),
" w1=", round(coef(model)[[2]], digits=5),
" w0=", round(coef(model)[[1]], digits=5),
" error=", round(mean(abs(training_dataframe_parsed$e)), digits=5))
)
# test the created model comparing it againts test-dataframe (hipothesys=h vs reality=y)
testing_dataframe_parsed$h =
coef(model)[[7]]*testing_dataframe_parsed$x6 +
coef(model)[[6]]*testing_dataframe_parsed$x5 +
coef(model)[[5]]*testing_dataframe_parsed$x4 +
coef(model)[[4]]*testing_dataframe_parsed$x3 +
coef(model)[[3]]*testing_dataframe_parsed$x2 +
coef(model)[[2]]*testing_dataframe_parsed$x1 +
coef(model)[[1]]*testing_dataframe_parsed$x0
testing_dataframe_parsed$e = testing_dataframe_parsed$y - testing_dataframe_parsed$h
# print MAE
print(paste0(" Comparing calculated weights against real test value"))
print(paste0(" MAE = ", mean(abs(testing_dataframe_parsed$e))))
# print R-squared values
print(paste0(" Multiple R-squared = ", summary(model)$r.squared))
print(paste0(" Adjusted R-squared = ", summary(model)$adj.r.squared))
ObtainedMAEs_lm = append(ObtainedMAEs_lm, mean(abs(testing_dataframe_parsed$e)))
#print the summary
summary(model)
invisible(readline(prompt = "Press a key to start next iteration"))
}
summary(model)
for (i in 1:10) {
# create partitions
set.seed(number)
number = number + 5
#select 80% of the data
training_data_in_indexes = createDataPartition(
csv_dataframe$Overall.rank,
times = 1,
p = 0.8,
list = FALSE
)
training_dataframe = csv_dataframe[training_data_in_indexes,] # get the 80% of the data for training
testing_dataframe = csv_dataframe[-training_data_in_indexes,] # the rest (20%) for testing
# adapt the format of the TRAINING dataframe
training_dataframe_parsed = data.frame(
x6 = training_dataframe$Social.support,
x5 = training_dataframe$Healthy.life.expectancy,
x4 = training_dataframe$Freedom.to.make.life.choices,
x3 = training_dataframe$Generosity,
x2 = training_dataframe$Perceptions.of.corruption,
x1 = training_dataframe$GDP.per.capita,
x0 = 1,
y  = training_dataframe$Score,
h  = 0,
e  = 0
)
# adapt the format of the TEST dataframe
testing_dataframe_parsed = data.frame(
x6 = testing_dataframe$Social.support,
x5 = testing_dataframe$Healthy.life.expectancy,
x4 = testing_dataframe$Freedom.to.make.life.choices,
x3 = testing_dataframe$Generosity,
x2 = testing_dataframe$Perceptions.of.corruption,
x1 = testing_dataframe$GDP.per.capita,
x0 = 1,
y  = testing_dataframe$Score,
h  = 0,
e  = 0
)
# use lm() function
model = lm(y ~ x1+x2+x3+x4+x5+x6, data = training_dataframe_parsed)
# add hypothesis and error values to the training dataframe
training_dataframe_parsed$h = predict(model, training_dataframe_parsed)
training_dataframe_parsed$e = training_dataframe_parsed$y - training_dataframe_parsed$h
# plot the trained model
print(ggplot(training_dataframe_parsed) +
geom_point(aes(x = x1, y = y, col = "Data")) +
geom_point(aes(x = x1, y = h, col = "Model hypothesis")) +
geom_line(aes(x = x1, y = h, col = "Model hypothesis")) +
labs(caption=paste0(
"  w6=", round(coef(model)[[7]], digits=4),
"  w5=", round(coef(model)[[6]], digits=4),
"  w4=", round(coef(model)[[5]], digits=4),
"  w3=", round(coef(model)[[4]], digits=4),
"  w2=", round(coef(model)[[3]], digits=4),
"  w1=", round(coef(model)[[2]], digits=4),
"  w0=", round(coef(model)[[1]], digits=4)
))
)
# print information about the trained model
print(paste0(" Calculated weights in training data and error"))
print(paste0(
" w6=", round(coef(model)[[7]], digits=5),
" w5=", round(coef(model)[[6]], digits=5),
" w4=", round(coef(model)[[5]], digits=5),
" w3=", round(coef(model)[[4]], digits=5),
" w2=", round(coef(model)[[3]], digits=5),
" w1=", round(coef(model)[[2]], digits=5),
" w0=", round(coef(model)[[1]], digits=5),
" error=", round(mean(abs(training_dataframe_parsed$e)), digits=5))
)
# test the created model comparing it againts test-dataframe (hipothesys=h vs reality=y)
testing_dataframe_parsed$h =
coef(model)[[7]]*testing_dataframe_parsed$x6 +
coef(model)[[6]]*testing_dataframe_parsed$x5 +
coef(model)[[5]]*testing_dataframe_parsed$x4 +
coef(model)[[4]]*testing_dataframe_parsed$x3 +
coef(model)[[3]]*testing_dataframe_parsed$x2 +
coef(model)[[2]]*testing_dataframe_parsed$x1 +
coef(model)[[1]]*testing_dataframe_parsed$x0
testing_dataframe_parsed$e = testing_dataframe_parsed$y - testing_dataframe_parsed$h
# print MAE
print(paste0(" Comparing calculated weights against real test value"))
print(paste0(" MAE = ", mean(abs(testing_dataframe_parsed$e))))
# print R-squared values
print(paste0(" Multiple R-squared = ", summary(model)$r.squared))
print(paste0(" Adjusted R-squared = ", summary(model)$adj.r.squared))
ObtainedMAEs_lm = append(ObtainedMAEs_lm, mean(abs(testing_dataframe_parsed$e)))
#print the summary
summary(model)
invisible(readline(prompt = "Press a key to start next iteration"))
}
